import { Meta, Markdown } from '@storybook/blocks';
import Shot from "../assets/shot_langchain.png";

<Meta title="Gallery/Base: Langchain" />

# Lexio RAG Demo with Langchain, ChromaDB, and OpenAI + PDF Highlights with PyMuPDF

This repository demonstrates how to build a Retrieval-Augmented Generation (RAG) system on PDF data using
Langchain, ChromaDB, PyMuPDF and the Lexio UI components. The demo showcases:

- **Advanced PDF Processing** with PyMuPDF for intelligent text extraction and highlighting
- **Real-time streaming** of responses (via Server-Sent Events)
- **Document retrieval** from a ChromaDB vector store
- **Modern React frontend** with Lexio UI components


<img src={Shot} alt="Screenshot of the demo" />

## Tech Stack

1. **FastAPI** (Python) for the backend
2. **React + TypeScript** frontend using [Lexio](https://github.com/Renumics/lexio) components
3. **PyMuPDF** for advanced PDF processing and text position extraction
4. **Langchain** for document processing and LLM integration
5. **ChromaDB** for vector storage and retrieval
6. **OpenAI** for embeddings and text generation

## Features Overview

1. **Advanced PDF Processing & Display**
   - Intelligent PDF text extraction with positional information
   - Automatic highlighting of relevant text passages
   - Precise bounding box calculation for text spans
   - Interactive PDF viewer with highlight overlay support

2. **Document Processing & Storage**
   - Automatic indexing of PDF documents placed in the `data` directory
   - Smart text chunking with positional metadata preservation
   - ChromaDB vector store for efficient retrieval

3. **Streaming Responses**
   - Real-time token streaming via Server-Sent Events (SSE)
   - Immediate feedback as responses are generated

4. **Conversation Context**
   - Support for follow-up questions
   - Maintains conversation history for contextual responses

5. **Modern UI Components**
   - Chat interface with streaming support
   - Interactive PDF viewer with highlight support
   - Clean query interface for natural language questions

## Setup & Installation

### Requirements

- Make (optional)
- Python 3.12 or higher
- Node.js 20 or higher
- OpenAI API key
- Modern web browser with SSE support

### Backend

1. **Clone this repository** and navigate into the demo `backend` folder:
```bash
git clone <repo_url>
cd examples/langchain/backend
```

2. **Create a virtual environment** and activate it:
```bash
python -m venv .venv
source .venv/bin/activate  # On Windows: .venv\Scripts\activate
```

3. **Install dependencies**:
```bash
pip install -e .
```

4. Create a `.env` file with your OpenAI API key:
```bash
echo "OPENAI_API_KEY=your-api-key-here" > .env
```

5. **Add your PDF documents** to the `data` directory

6. **Index** the documents:
```bash
index-files
```

7. **Start** the backend server:
```bash
run-server
```

### Frontend

1. **Navigate to the frontend directory:**
```bash
cd examples/langchain/frontend
```

2. **Install dependencies:**
```bash
npm install
```

3. **Start** the development server:
```bash
npm run dev
```

4. Open http://localhost:5173 in your browser

## Usage

1. **Open the frontend** in your browser.
   Typically at [http://localhost:5173](http://localhost:5173).

2. **Ask a question** about the PDFs that you added.
   - The system will retrieve relevant chunks from ChromaDB and stream a response from the OpenAI model.

3. **View sources**
   - In the SourcesDisplay component, youâ€™ll see clickable references.
   - Click on any source link to open it in the ContentDisplay in the middle.


[//]: # (TODO: add usage instructions + add Backend and frontend highlights + next steps)
---